{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf10f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           _id                                  Name of movie  \\\n",
      "0     657aadbf61afffb42be104e3                       The Shawshank Redemption   \n",
      "1     657aadbf61afffb42be104e4                                  The Godfather   \n",
      "2     657aadbf61afffb42be104e5                                The Dark Knight   \n",
      "3     657aadbf61afffb42be104e6                               Schindler's List   \n",
      "4     657aadbf61afffb42be104e7  The Lord of the Rings: The Return of the King   \n",
      "...                        ...                                            ...   \n",
      "2424  657aadbf61afffb42be10e5b                       The Shawshank Redemption   \n",
      "2425  657aadbf61afffb42be10e5c                       The Shawshank Redemption   \n",
      "2426  657aadbf61afffb42be10e5d                                  The Godfather   \n",
      "2427  657aadbf61afffb42be10e5e                       The Shawshank Redemption   \n",
      "2428  657aadbf61afffb42be10e5f                                  The Godfather   \n",
      "\n",
      "     Year of relase  Watchtime  Movie Rating      Votes Gross collection  \\\n",
      "0              1994        142           9.3  28,12,020          $28.34M   \n",
      "1              1972        175           9.2  19,59,769         $134.97M   \n",
      "2              2008        152           9.0  27,93,712         $534.86M   \n",
      "3              1993        195           9.0  14,13,613          $96.90M   \n",
      "4              2003        201           9.0  19,25,356         $377.85M   \n",
      "...             ...        ...           ...        ...              ...   \n",
      "2424           1994        142           9.3  28,12,020          $28.34M   \n",
      "2425           1994        142           9.3  28,12,020          $28.34M   \n",
      "2426           1972        175           9.2  19,59,769         $134.97M   \n",
      "2427           1994        142           9.3  28,12,020          $28.34M   \n",
      "2428           1972        175           9.2  19,59,769         $134.97M   \n",
      "\n",
      "                  Director                                               Star  \\\n",
      "0           Frank Darabont  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton'...   \n",
      "1     Francis Ford Coppola  ['Marlon Brando', 'Al Pacino', 'James Caan', '...   \n",
      "2        Christopher Nolan  ['Christian Bale', 'Heath Ledger', 'Aaron Eckh...   \n",
      "3         Steven Spielberg  ['Liam Neeson', 'Ralph Fiennes', 'Ben Kingsley...   \n",
      "4            Peter Jackson  ['Elijah Wood', 'Viggo Mortensen', 'Ian McKell...   \n",
      "...                    ...                                                ...   \n",
      "2424        Frank Darabont  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton'...   \n",
      "2425        Frank Darabont  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton'...   \n",
      "2426  Francis Ford Coppola  ['Marlon Brando', 'Al Pacino', 'James Caan', '...   \n",
      "2427        Frank Darabont  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton'...   \n",
      "2428  Francis Ford Coppola  ['Marlon Brando', 'Al Pacino', 'James Caan', '...   \n",
      "\n",
      "     Rating_Category  \n",
      "0          Very High  \n",
      "1          Very High  \n",
      "2               High  \n",
      "3               High  \n",
      "4               High  \n",
      "...              ...  \n",
      "2424       Very High  \n",
      "2425       Very High  \n",
      "2426       Very High  \n",
      "2427       Very High  \n",
      "2428       Very High  \n",
      "\n",
      "[2429 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import data from mongoDB\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(\"localhost\", 27017)\n",
    "db = client[\"BIGDATA-PROJECT\"]\n",
    "collection = db[\"MOVIES1\"] \n",
    "cursor = collection.find()\n",
    "data=pd.DataFrame(list(cursor))\n",
    "client.close()\n",
    "data=data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef65500",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_kernel\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Handling missing values in all columns\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Fill missing values with an empty string for all columns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Assuming the dataset includes features 'Name of movie', 'Director', 'Star', and 'Rating_Category' as the target\u001b[39;00m\n\u001b[0;32m     13\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of movie\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStar\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split                         #LOGISCTIC REGRESSION MODEL\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n",
    "# Handling missing values in all columns\n",
    "data = data.fillna('')  # Fill missing values with an empty string for all columns\n",
    "\n",
    "# Assuming the dataset includes features 'Name of movie', 'Director', 'Star', and 'Rating_Category' as the target\n",
    "features = ['Name of movie', 'Director', 'Star']\n",
    "target = 'Rating_Category'  # Assuming 'Rating_Category' is the column for movie rating categories\n",
    "\n",
    "# Convert non-string values to strings in selected columns\n",
    "for feature in features:\n",
    "    data[feature] = data[feature].astype(str)\n",
    "\n",
    "# Combine selected features into a single column\n",
    "data['combined_features'] = data[features].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get movie suggestions based on movie title\n",
    "def get_recommendations(movie_title, cosine_sim=cosine_sim, data=data):\n",
    "    idx = data[data['Name of movie'].str.lower() == movie_title.lower()].index\n",
    "    if len(idx):\n",
    "        idx = idx[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        return data['Name of movie'].iloc[movie_indices]\n",
    "    else:\n",
    "        return \"Movie not found in the database.\"\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "# Handling missing values in all columns\n",
    "data = data.fillna('')  # Fill missing values with an empty string\n",
    "\n",
    "# Combine selected features into a single column\n",
    "features = ['Name of movie', 'Director', 'Star']\n",
    "data['combined_features'] = data[features].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Define the target column\n",
    "target = 'Rating_Category'  # Assuming 'Movie_Rating_Category' is the column for movie rating categories\n",
    "\n",
    "# Handling class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "tfidf_matrix_res, target_res = oversampler.fit_resample(tfidf_matrix, data[target])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_res, target_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Random Forest Classifier model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Random Forest Classifier\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Generate a classification report for Random Forest Classifier\n",
    "rf_report = classification_report(y_test, rf_predictions)\n",
    "print(\"Random Forest Classifier Report:\\n\", rf_report)\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "def get_recommendations(movie_title, cosine_sim=linear_kernel(tfidf_matrix_res, tfidf_matrix_res), data=data):\n",
    "    idx = data[data['Name of movie'].str.lower() == movie_title.lower()].index\n",
    "    if not idx.empty:  # Check if the index is not empty\n",
    "        idx = idx[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "        # Ensure movie indices are within the DataFrame's bounds\n",
    "        valid_indices = [idx for idx in movie_indices if idx < len(data)]\n",
    "        return data['Name of movie'].iloc[valid_indices]\n",
    "    else:\n",
    "        return \"Movie not found in the database.\"\n",
    "\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d42a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                   0.96      1.00      0.98       119\n",
      "        High       1.00      1.00      1.00       111\n",
      "         Low       0.76      0.78      0.77       129\n",
      "    Moderate       0.77      0.71      0.74       119\n",
      "   Very High       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           0.89       591\n",
      "   macro avg       0.90      0.90      0.90       591\n",
      "weighted avg       0.89      0.89      0.89       591\n",
      "\n",
      "\n",
      "Recommendations for 'Happiness':\n",
      " 960         Moneyball\n",
      "375          Magnolia\n",
      "289     Mary and Max.\n",
      "1569    Mary and Max.\n",
      "993         25th Hour\n",
      "Name: Name of movie, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# Handling missing values in all columns\n",
    "data = data.fillna('')  # Fill missing values with an empty string for all columns\n",
    "\n",
    "# Assuming the dataset includes features 'Name of movie', 'Director', 'Star', and 'Movie_Rating_Category' as the target\n",
    "features = ['Name of movie', 'Director', 'Star']\n",
    "target = 'Rating_Category'  # Assuming 'Movie_Rating_Category' is the column for movie rating categories\n",
    "\n",
    "# Combine selected features into a single column\n",
    "data['combined_features'] = data[features].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Handling class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "tfidf_matrix_res, target_res = oversampler.fit_resample(tfidf_matrix, data[target])\n",
    "\n",
    "# Split resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_res, target_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train an SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using SVM classifier\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Generate a classification report for SVM classifier\n",
    "svm_report = classification_report(y_test, svm_predictions)\n",
    "print(\"SVM Classifier Report:\\n\", svm_report)\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "def get_recommendations(movie_title, cosine_sim=linear_kernel(tfidf_matrix_res, tfidf_matrix_res), data=data):\n",
    "    idx = data[data['Name of movie'].str.lower() == movie_title.lower()].index\n",
    "    if not idx.empty:  # Check if the index is not empty\n",
    "        idx = idx[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
    "\n",
    "        movie_indices = [i[0] for i in sim_scores if i[0] < len(data)]  # Filter indices within DataFrame bounds\n",
    "\n",
    "        return data['Name of movie'].iloc[movie_indices]\n",
    "    else:\n",
    "        return \"Movie not found in the database.\"\n",
    "\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "645eb19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                   0.89      0.94      0.91       119\n",
      "        High       0.97      1.00      0.99       111\n",
      "         Low       0.66      0.67      0.67       129\n",
      "    Moderate       0.73      0.65      0.68       119\n",
      "   Very High       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           0.85       591\n",
      "   macro avg       0.85      0.85      0.85       591\n",
      "weighted avg       0.84      0.85      0.84       591\n",
      "\n",
      "\n",
      "Recommendations for 'Happiness':\n",
      " 960             Moneyball\n",
      "375              Magnolia\n",
      "289         Mary and Max.\n",
      "1569        Mary and Max.\n",
      "993             25th Hour\n",
      "677       Midnight Cowboy\n",
      "706     Kramer vs. Kramer\n",
      "877                  Zulu\n",
      "979           Dark Waters\n",
      "983              Rushmore\n",
      "Name: Name of movie, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "# Handling missing values in all columns\n",
    "data = data.fillna('')  # Fill missing values with an empty string\n",
    "\n",
    "# Combine selected features into a single column\n",
    "features = ['Name of movie', 'Director', 'Star']\n",
    "data['combined_features'] = data[features].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Define the target column\n",
    "target = 'Rating_Category'  # Assuming 'Movie_Rating_Category' is the column for movie rating categories\n",
    "\n",
    "# Handling class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "tfidf_matrix_res, target_res = oversampler.fit_resample(tfidf_matrix, data[target])\n",
    "\n",
    "# Split resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_res, target_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Gradient Boosting Classifier\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Generate a classification report for Gradient Boosting Classifier\n",
    "gb_report = classification_report(y_test, gb_predictions)\n",
    "print(\"Gradient Boosting Classifier Report:\\n\", gb_report)\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "def get_recommendations(movie_title, cosine_sim=linear_kernel(tfidf_matrix_res, tfidf_matrix_res), data=data):\n",
    "    idx = data[data['Name of movie'].str.lower() == movie_title.lower()].index\n",
    "    if not idx.empty:\n",
    "        idx = idx[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = [i for i in sim_scores if i[0] < len(data)]\n",
    "        sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
    "\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        return data['Name of movie'].iloc[movie_indices]\n",
    "    else:\n",
    "        return \"Movie not found in the database.\"\n",
    "\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af79515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                   0.88      1.00      0.93       119\n",
      "        High       0.97      1.00      0.99       111\n",
      "         Low       0.75      0.65      0.70       129\n",
      "    Moderate       0.76      0.74      0.75       119\n",
      "   Very High       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           0.87       591\n",
      "   macro avg       0.87      0.88      0.87       591\n",
      "weighted avg       0.87      0.87      0.87       591\n",
      "\n",
      "\n",
      "Recommendations for 'Happiness':\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "# Data preprocessing: handling missing values, feature engineering, etc.\n",
    "\n",
    "# Assuming 'data' contains columns: 'Name of movie', 'Director', 'Star', 'Rating_Category'\n",
    "\n",
    "# Handling missing values in all columns\n",
    "data = data.fillna('')  # Fill missing values with an empty string\n",
    "\n",
    "# Combine selected features into a single column\n",
    "features = ['Name of movie', 'Director', 'Star']\n",
    "data['combined_features'] = data[features].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Define the target column\n",
    "target = 'Rating_Category'  # Assuming 'Rating_Category' is the column for movie rating categories\n",
    "\n",
    "# Handling class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "tfidf_matrix_res, target_res = oversampler.fit_resample(tfidf_matrix, data[target])\n",
    "\n",
    "# Split resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_res, target_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Decision Tree Classifier\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Generate a classification report for Decision Tree Classifier\n",
    "dt_report = classification_report(y_test, dt_predictions)\n",
    "print(\"Decision Tree Classifier Report:\\n\", dt_report)\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "def get_recommendations(movie_title, cosine_sim=linear_kernel(tfidf_matrix_res, tfidf_matrix_res), data=data):\n",
    "    # Implement the recommendation function as mentioned in the previous examples\n",
    "    pass\n",
    "\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################_______________________##################____________###############_________#________###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54753d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIES DAATA DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"MOVIES DAATA DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6f42a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MulticlassClassificationEvaluator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Assuming 'data' is a DataFrame in PySpark with columns: 'Name of movie', 'Director', 'Star', 'Rating_Category'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# SparkSession creation\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieRecommendation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Handling missing values by replacing nulls with empty strings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sparkConf)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         SparkContext(conf\u001b[38;5;241m=\u001b[39mconf \u001b[38;5;129;01mor\u001b[39;00m SparkConf())\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\site-packages\\pyspark\\java_gateway.py:100\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\anaconda4\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Assuming 'data' is a DataFrame in PySpark with columns: 'Name of movie', 'Director', 'Star', 'Rating_Category'\n",
    "# SparkSession creation\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
    "\n",
    "# Handling missing values by replacing nulls with empty strings\n",
    "data = data.fillna('')\n",
    "\n",
    "# Combining selected features into a single column\n",
    "data = data.withColumn('combined_features', concat_ws(' ', col('Name of movie'), col('Director'), col('Star')))\n",
    "\n",
    "# Tokenizing and removing stopwords\n",
    "tokenizer = Tokenizer(inputCol=\"combined_features\", outputCol=\"tokens\")\n",
    "data = tokenizer.transform(data)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "data = remover.transform(data)\n",
    "\n",
    "# TF-IDF transformation\n",
    "hashingTF = HashingTF(inputCol=\"filtered_tokens\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(data)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "data = idfModel.transform(featurizedData)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Logistic Regression model initialization and training\n",
    "lr = LogisticRegression(labelCol=\"Rating_Category\", featuresCol=\"features\", maxIter=1000)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Making predictions\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# Generating a classification report\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Rating_Category\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Function to get movie suggestions based on movie title\n",
    "def get_recommendations(movie_title):\n",
    "    movie = data.filter(col(\"Name of movie\").like(f\"%{movie_title}%\")).select(\"Name of movie\").take(1)\n",
    "    if movie:\n",
    "        similar_movies = lrModel.stages[-1].findSimilarItems(int(movie[0][0]), 10)\n",
    "        similar_movie_indices = [row[0] for row in similar_movies]\n",
    "        return data.filter(col(\"Name of movie\").isin(similar_movie_indices)).select(\"Name of movie\").rdd.flatMap(lambda x: x).collect()\n",
    "    else:\n",
    "        return \"Movie not found in the database.\"\n",
    "\n",
    "# Example: Get movie recommendations for a given movie title\n",
    "suggestions = get_recommendations('Happiness')\n",
    "print(\"\\nRecommendations for 'Happiness':\\n\", suggestions)\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795722a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
